
Question we are focusing on: 
  - How to create methods for AI to capture a deeper understanding of text?

Human perception or rather, humans learn to ignore vast majority of things and focus only on what is relevant at the moment 
  - This may be a byproduct due to natures limitation in storage capacity
    - However, it may also be an advantage for thinking, producing insight because if everything was constantly encoding in the brian, 
    you would run into the information overload problem 

AI is probably doing something similar as well
  - In CNN, the AI has the entire image as input but overtime, the AI probably learns which features are important for the task
  - In NLM, something similar is probably going on; AI is learning which words are important for various tasks  

* Self-awareness? 
  - stimulating self-awareness
    - BPL? Modules?

PFC? - BPL? Modules?

- How would the cell-assemblies be formed? (Brain computation as cell assemblies paper)
  - ie. the AI makes a mistake, how would it learn to not make that same mistake next time? 
  ^ Cell-assemblies are attractive since they can represent persisted reverbatory activity (continued thought when the stimulus isn't present)
    - Interfacilitation between wake/sleep and cell-assemblies?

ability to have self-awareness (important for deeper understanding, efficient learning, learn drive)

^ Maybe it's not to view this in terms of self-awareness; rather, it is how generalizations/hypotheses are formed and corrected in the brain? 
  - A key part of intelligence is the ability to form/find abstractions/generalizations in data 
    - ^ IQ tests are testing for this (much of scientific research is this)
  - ^Clearly this is happening in the brain from birth, before "meta-cognition"; 
    - Generalizations in DNN's form via combinations of different inputs converging into some subset of neurons (multimodal neurons)
    - How do these generalizations form via cell-assemblies and how can one explain reasoning models?
      - How do we explain how arthimetic/logic/reasoning, etc. is learned? 
        - Clearly this occurs to some degree in DNN's although I am not sure if this is a byproduct of interpolation 
        (just Autoassociative nets; If we are going along with this assumption, then why would we need cell-assemblies?)
          - Maybe it's interfacilations with the PFC that allow for more foundational (thinking)-models to form? 
            *TODO: Read Roll's paper on PFC 



Interesting Resources: 
- Language Learning and Program Synthesis: 
  - https://sites.google.com/view/anshula-research-blog/entries/language-learning-and-program-synthesis 



(For us) Viewing research almost as feature upgrades to test
- ^ Speeds up the entire process; rather than viewing it as writing a paper or explaining your line of reasoning, etc.




